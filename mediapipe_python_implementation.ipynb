{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9691c995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monster\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time \n",
    "\n",
    "# !pip install mediapipe\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c470cd",
   "metadata": {},
   "source": [
    "## 1.Face Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness = 1, circle_radius = 1)\n",
    "\n",
    "cap = cv2.VideoCapture(\"face.mp4\")\n",
    "\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence = 0.5,\n",
    "                           min_tracking_confidence = 0.5) as face_mesh:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        start = time.time()\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mesh = face_mesh.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if mesh.multi_face_landmarks:\n",
    "            for face_landmarks in mesh.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(image = frame,\n",
    "                                          landmark_list = face_landmarks,\n",
    "                                          connections = mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                                          landmark_drawing_spec = drawing_spec,\n",
    "                                          connection_drawing_spec = drawing_spec)\n",
    "        \n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        \n",
    "        if total_time == 0:\n",
    "            total_time = 1\n",
    "        \n",
    "        fps = 1/total_time\n",
    "                                          \n",
    "        cv2.putText(frame, \n",
    "                    f\"FPS:{int(fps)}\", \n",
    "                    (30,90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.2,\n",
    "                    (0,255,0),\n",
    "                    2)\n",
    "                                          \n",
    "        cv2.imshow(\"Camera\",frame)\n",
    "        if cv2.waitKey(10) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29c5c5",
   "metadata": {},
   "source": [
    "## 2. Hand Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(\"hand.mp4\")\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence = 0.5,\n",
    "                           min_tracking_confidence = 0.5) as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        start = time.time()\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if mesh.multi_hand_landmarks:\n",
    "            for hand_landmarks in mesh.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image = frame,\n",
    "                                          landmark_list = hand_landmarks,\n",
    "                                          connections = mp_hand.HAND_CONNECTIONS)\n",
    "        \n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        \n",
    "        if total_time == 0:\n",
    "            total_time = 1\n",
    "        \n",
    "        fps = 1/total_time\n",
    "                                          \n",
    "        cv2.putText(frame, \n",
    "                    f\"FPS:{int(fps)}\", \n",
    "                    (30,90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.2,\n",
    "                    (0,255,0),\n",
    "                    2)\n",
    "                                          \n",
    "        cv2.imshow(\"Camera\",frame)\n",
    "        if cv2.waitKey(10) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ecf37",
   "metadata": {},
   "source": [
    "## 3. Pose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93bfc182",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\OUZ~1\\AppData\\Local\\Temp/ipykernel_12812/3717160911.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "cap = cv2.VideoCapture(\"2.mp4\")\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence = 0.5,\n",
    "                           min_tracking_confidence = 0.5) as pose:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = pose.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "         \n",
    "        mp_drawing.draw_landmarks(frame,\n",
    "                                  result.pose_landmarks,\n",
    "                                  mp_pose.POSE_CONNECTIONS,\n",
    "                                  landmark_drawing_spec = mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                            \n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        \n",
    "        if total_time == 0:\n",
    "            total_time = 1\n",
    "        \n",
    "        fps = 1/total_time\n",
    "                                          \n",
    "        cv2.putText(frame, \n",
    "                    f\"FPS:{int(fps)}\", \n",
    "                    (30,90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.2,\n",
    "                    (0,255,0),\n",
    "                    2)\n",
    "                                          \n",
    "        cv2.imshow(\"Camera\",frame)\n",
    "        if cv2.waitKey(10) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
